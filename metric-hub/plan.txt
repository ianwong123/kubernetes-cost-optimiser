API Gateway Aggregator
Api to handle json metrics:
1. POST /metrics/cost
2. POST /metrics/forecast

Create the http server to handle requests to endpoints:
1. POST /metrics/cost  FROM port 8000
2. POST /metrics/forecast FROM port 8002

As of the moment, the namespace with the highest cost drives the current hourly cost
Note*: The current_hourly_cost_gbp is driven by the namespace that inccurs the highest cost
 Forecast result should never be stored in in redis
merged result should never be stored in redis
====================================================================
Typical payload in POST /metrics/cost request includes:
====================================================================
{
  "source": "cost-engine",
  "timestamp": "2024-01-01T12:00:00Z",
  "namespace": "default",
  "cluster_totals": {
    "vm_count": 3,
    "current_hourly_cost_gbp": 1.25
  },
  "deployments": [
    {
      "name": "adservice",
      "current_requests": {
        "cpu_cores": 2.0,
        "memory_mb": 4096
      },
      "current_usage": {
        "cpu_cores": 0.4,
        "memory_mb": 512
      }
    },
    {
      "name": "cartservice",
      "current_requests": {
        "cpu_cores": 1.5,
        "memory_mb": 2048
      },
      "current_usage": {
        "cpu_cores": 0.8,
        "memory_mb": 1024
      }
    }
  ]
}
====================================================================
Typical payload in POST /metrics/forecast request includes:
====================================================================
{
  "source": "forecast",
  "timestamp": "2024-01-01T12:00:00Z",
  "namespace": "default",
  "deployments": [
    {
      "name": "adservice",
      "predict_peak_24h": {
        "cpu_cores": 0.55,
        "memory_mb": 600
      }
    },
    {
      "name": "cartservice",
      "predict_peak_24h": {
        "cpu_cores": 1.2,
        "memory_mb": 1200
      }
    }
  ]
}
====================================================================
Aggregator:
====================================================================
Redis State Schema
Key: cost:latest
Value: <latest cost payload as JSON>
====================================================================
every minute when a cost payload arrives:
====================================================================
1. store the latest payload - overwriting the previous one - holds the latest truth
2. at the same time for each deployment, check thresholds
4. for depoyment that violates threshold, attach a key has a value 'high waste' or some other value
3. push deployments that violate threshold in to message queue
4. overwrite the previous cost data


What gets pushed to queue for each deployment in from costpayload:
{
  "reason": "high-waste",
  "source": "cost-engine",
  "namespace": "default",
  "deployment": {
    "name": "adservice",
    "current_requests": { cpu_cores: ... , memory_mb: ... },
    "current_usage": { cpu_cores: ..., memory_mb: ... }
  },
  "cluster_info": {
    "vm_count": 3,
    "current_hourly_cost_gbp": 1.25
  }
}
Threshold logic:
check thresholds for each deployment 
    1. waste = (req - usage) / req
    2. utilisation = usage / req
if waste > 0.5 or utilisation > 0.85
    1. check cooldown timestamp (last trigger timestamp)
    2. if cooldown expired (> 30 min)
        - trigger ai agent with deployment data
        - update last trigger timestamp 

====================================================================
when a forecast payload arrives:
====================================================================

1. retrieve all the latest cost data
2. merge/attach new forecast fields  onto cost data - specifically:
   - for each deployment:
    - find the matching deployment in forecast payload
    - add the forecast field
    - "predict_peak_24h: {cpu_cores, memory_mb}
    - obtained merged data
3. check thresholds again
4. push deployments that violate threholds into message queue
5. throw away merged result/dont store/logging should be done in other service, not redis

What gets pushed to queue for each deployment in from after merging cost and forecast:
{
  "reason": "high-waste",
  "source": "aggregator",
  "namespace": "default",
  "deployment": {
    "name": "adservice",
    "current_requests": { cpu_cores: ... , memory_mb: ... },
    "current_usage": { cpu_cores: ..., memory_mb: ... },
    "predict_peak_24h": { cpu_cores: ..., memory_mb: ... },
  },
  "cluster_info": {
    "vm_count": 3,
    "current_hourly_cost_gbp": 1.25
  }
}

check thresholds for each deployment:
    - pred_cpu_peak > req_cpu * 0.9 (predicted capacity risk)
    - waste > 0.4 AND pred_cpu_peak < req_cpu * 0.6 (safe to downscale)
if any threshold crossed:
    - check cooldown (last_trigger timestamp)
    - if cooldown expired (>30min):
        trigger AI agent with combined state
        update last_trigger timestamp
====================================================================





